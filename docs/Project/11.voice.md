# 阿里云语音识别

书接上回，上一篇 EventSource 已经完成正常文字输入对话，下面来完成语音识别转文字加对话。你也可以直接访问[阿里语音智能交互](https://help.aliyun.com/zh/isi/getting-started/obtain-an-access-token?spm=a2c4g.11186623.0.0.1a1d2e6dFZnW8e#title-u2l-tam-gms)

## H5 端呼出麦克风

```js
/**
 * @description 开始录音
 */

const startRecording = async () => {
  // 这里先获取 token 和 appKey 根据实际业务修改
  const { data } = await request.get('/voice/getTokenAndAppKey');
  await connectWebSocket(sm4Decrypt(data.app_key), sm4Decrypt(data.access_token));
  try {
    audioStream = await navigator.mediaDevices.getUserMedia({ audio: true }); // 获取音频流
    audioContext = new window.AudioContext({ sampleRate: 16000 }); // 创建音频上下文 16000 采样率
    audioInput = audioContext.createMediaStreamSource(audioStream); // 创建音频输入

    scriptProcessor = audioContext.createScriptProcessor(2048, 1, 1); // 创建脚本处理器

    scriptProcessor.onaudioprocess = (event) => {
      const inputData = event.inputBuffer.getChannelData(0);
      const inputData16 = new Int16Array(inputData.length);
      for (let i = 0; i < inputData.length; ++i) {
        inputData16[i] = Math.max(-1, Math.min(1, inputData[i])) * 0x7fff;
      }
      if (websocket && websocket.readyState === WebSocket.OPEN) {
        websocket.send(inputData16.buffer);
      }
    }; // 连接音频输入到脚本处理器
    audioInput.connect(scriptProcessor);
    scriptProcessor.connect(audioContext.destination);
    startVoice.value = true;
  } catch (e) {
    console.log('e--------->', e);
  }
};

/**
 * @description 打开WebSocket连接 阿里云Web端的语音识别是通过WebSocket协议连接的
 */
const connectWebSocket = (appKey, token) => {
  const socketUrl = `wss://nls-gateway.cn-shanghai.aliyuncs.com/ws/v1?token=${token}`;
  websocket = new WebSocket(socketUrl);
  websocket.onopen = function () {
    updateStatus('已连接');
    logMessage('WebSocket 已连接');

    var startTranscriptionMessage = {
      header: {
        appkey: appKey,
        namespace: 'SpeechTranscriber',
        name: 'StartTranscription',
        task_id: uuidv4().replace(/-/g, ''),
        message_id: uuidv4().replace(/-/g, ''),
      },
      payload: {
        format: 'pcm',
        sample_rate: 16000,
        enable_intermediate_result: true,
        enable_punctuation_prediction: true,
        enable_inverse_text_normalization: true,
      },
    };

    websocket.send(JSON.stringify(startTranscriptionMessage));
  };

  websocket.onmessage = function (event) {
    const message = JSON.parse(event.data);
    if (_.has(message.payload, 'result')) {
      voiceText.value = `${voiceText.value}${message.payload.result}`;
    }
  };

  websocket.onerror = function (event) {
    updateStatus('错误');
  };

  websocket.onclose = function () {
    updateStatus('断开连接');
  };
};

/**
 * @description 结束录音
 */
const stopRecording = () => {
  if (scriptProcessor) scriptProcessor.disconnect();
  if (audioInput) audioInput.disconnect();
  if (audioStream) audioStream.getTracks().forEach((track) => track.stop());
  if (audioContext) audioContext.close();
  isConnected.value = false;
};
```

以上代码中，我们通过 `navigator.mediaDevices.getUserMedia` 获取到音频流，然后通过 `AudioContext` 创建音频上下文，将音频流输入到脚本处理器，然后通过 WebSocket 连接阿里云语音识别服务，将音频流发送到服务端进行语音识别。谢谢阅读
